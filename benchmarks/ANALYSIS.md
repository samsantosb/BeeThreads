# bee-threads Benchmark Analysis

**Data:** 2025-12-12  
**Ambiente:** Docker (Node 20 Alpine / Bun 1)  
**Workers:** 11 CPUs

---

## Node.js Results

### DiagnÃ³stico de SerializaÃ§Ã£o (100K objetos)

| MÃ©todo | Pack | Unpack | Total | vs structuredClone |
|--------|------|--------|-------|-------------------|
| **structuredClone** | 172.44ms | 159.84ms | **332.28ms** | baseline |
| **AutoPack** | 19.38ms | 57.35ms | **76.73ms** | **4.3x mais rÃ¡pido** âœ… |

> ğŸ”‘ **Insight:** AutoPack Ã© 4.3x mais rÃ¡pido que structuredClone para objetos!

---

### CPU-HEAVY (1000 Math iterations per item)

| Size | RAW | BEE.TURBO | BEE.WORKER.TURBO | PISCINA |
|------|-----|-----------|------------------|---------|
| 10K | 412ms | **72ms (5.72x)** âœ… | **66ms (6.23x)** âœ… | 400ms (1.03x) |
| 100K | 4,099ms | **824ms (4.97x)** âœ… | **767ms (5.34x)** âœ… | 1,065ms (3.85x) âœ… |
| 1M | 37,494ms | **10,108ms (3.71x)** âœ… | **9,608ms (3.90x)** âœ… | 9,516ms (3.94x) âœ… |

> ğŸ”‘ **Insight:** Para operaÃ§Ãµes CPU-heavy, BEE.TURBO e BEE.WORKER.TURBO sÃ£o **5-6x mais rÃ¡pidos** que RAW!

---

### CPU-LIGHT (simple x * 2 + 1)

| Size | RAW | BEE.TURBO | BEE.WORKER.TURBO | PISCINA |
|------|-----|-----------|------------------|---------|
| 10K | 0.39ms | 15ms âŒ | 108ms âŒ | 768ms âŒ |
| 100K | 7.69ms | 33ms âŒ | 1,073ms âŒ | 818ms âŒ |
| 1M | 141ms | 358ms âŒ | 6,816ms âŒ | 979ms âŒ |

> âš ï¸ **Insight:** Para operaÃ§Ãµes simples, o overhead de workers Ã© MAIOR que o benefÃ­cio. Use RAW.

---

### OBJECT TRANSFORM (AutoPack territory)

| Size | RAW | BEE.TURBO | BEE.WORKER.TURBO | PISCINA |
|------|-----|-----------|------------------|---------|
| 10K | 44ms | 94ms (0.47x) âŒ | 99ms (0.45x) âŒ | 418ms âŒ |
| 100K | 433ms | 460ms (0.94x) â†’ | 841ms (0.52x) âŒ | 880ms âŒ |
| 1M | 6,022ms | 7,311ms (0.82x) âŒ | 22,731ms âŒ | 10,051ms âŒ |

> âš ï¸ **Insight:** TransformaÃ§Ã£o de objetos simples nÃ£o compensa paralelizaÃ§Ã£o. O overhead de serializaÃ§Ã£o domina.

---

### SerializaÃ§Ã£o: number[]

| Size | structuredClone | JSON | packNumberArray | SharedArrayBuffer |
|------|-----------------|------|-----------------|-------------------|
| 1K | 0.38ms | 0.61ms | **0.07ms (5.4x)** âœ… | 0.09ms (4.2x) âœ… |
| 10K | 3.99ms | 3.48ms | **0.28ms (14.3x)** âœ… | 0.78ms (5.1x) âœ… |
| 100K | 43.23ms | 35.61ms | **0.87ms (49.7x)** âœ… | 3.64ms (11.9x) âœ… |
| 500K | 264.05ms | 226.83ms | **5.61ms (47.1x)** âœ… | 7.34ms (36.0x) âœ… |

> ğŸ”‘ **Insight:** `packNumberArray` Ã© atÃ© **50x mais rÃ¡pido** que structuredClone para arrays numÃ©ricos!

---

### SerializaÃ§Ã£o: string[]

| Size | structuredClone | JSON | packStringArray |
|------|-----------------|------|-----------------|
| 1K | 0.47ms | **0.12ms (3.9x)** âœ… | 0.99ms âŒ |
| 10K | 4.86ms | **1.57ms (3.1x)** âœ… | 3.28ms (1.5x) âœ… |
| 100K | 63.34ms | **16.34ms (3.9x)** âœ… | 46.37ms (1.4x) âœ… |
| 500K | 397.20ms | **139.43ms (2.9x)** âœ… | ERROR (buffer limit) |

> âš ï¸ **Insight:** Para strings, JSON Ã© mais rÃ¡pido que AutoPack! packStringArray tem limite de 16MB.

---

## Bun Results

### DiagnÃ³stico de SerializaÃ§Ã£o (100K objetos)

| MÃ©todo | Pack | Unpack | Total | vs structuredClone |
|--------|------|--------|-------|-------------------|
| **structuredClone** | 100.78ms | 100.72ms | **201.5ms** | baseline |
| **AutoPack** | 21.19ms | 18.64ms | **39.83ms** | **5.1x mais rÃ¡pido** âœ… |

> ğŸ”‘ **Insight:** Bun + AutoPack = 5x mais rÃ¡pido que structuredClone!

---

### Bun vs Node: Raw Performance (100K items)

| OperaÃ§Ã£o | Node | Bun | Speedup |
|----------|------|-----|---------|
| RAW map (light) | 415.82ms | **10.97ms** | **38x** ğŸš€ |
| RAW map (heavy) | 1808.52ms | **979.38ms** | **1.8x** |
| structuredClone | 332.28ms | **201.5ms** | **1.6x** |
| AutoPack | 76.73ms | **39.83ms** | **1.9x** |

> ğŸš€ **Insight:** Bun Ã© atÃ© **38x mais rÃ¡pido** que Node para operaÃ§Ãµes leves!

---

### CPU-HEAVY (Bun) - 1000 Math iterations per item

| Size | RAW | BEE.TURBO | BEE.WORKER.TURBO |
|------|-----|-----------|------------------|
| 10K | 237ms | **75ms (3.16x)** âœ… | **60ms (3.92x)** âœ… |
| 100K | 2,278ms | **712ms (3.20x)** âœ… | **530ms (4.30x)** âœ… |
| 500K | 11,868ms | **4,935ms (2.40x)** âœ… | **2,595ms (4.57x)** âœ… |

> ğŸ”‘ **Insight:** No Bun, BEE.WORKER.TURBO Ã© ainda **MAIS RÃPIDO** que BEE.TURBO! AtÃ© 4.57x speedup!

---

### CPU-LIGHT (Bun) - simple x * 2 + 1

| Size | RAW | BEE.TURBO | BEE.WORKER.TURBO |
|------|-----|-----------|------------------|
| 10K | 0.25ms | 1.98ms âŒ | 54ms âŒ |
| 100K | 0.94ms | 5.40ms âŒ | 428ms âŒ |
| 500K | 2.92ms | 19.65ms âŒ | 2,170ms âŒ |

> âš ï¸ **Insight:** Bun Ã© TÃƒO rÃ¡pido em single-thread que workers NÃƒO compensam para operaÃ§Ãµes simples!

---

### OBJECT TRANSFORM (Bun)

| Size | RAW | BEE.TURBO | BEE.WORKER.TURBO |
|------|-----|-----------|------------------|
| 10K | 0.71ms | 18.62ms âŒ | 38.52ms âŒ |
| 100K | 8.33ms | 109.63ms âŒ | 99.53ms âŒ |
| 500K | 51.63ms | 667.62ms âŒ | 764.10ms âŒ |

> âš ï¸ **Insight:** Para objetos simples, Bun single-thread Ã© 10x mais rÃ¡pido que com workers!

---

### SerializaÃ§Ã£o: number[] (Bun)

| Size | structuredClone | JSON | packNumberArray | SharedArrayBuffer |
|------|-----------------|------|-----------------|-------------------|
| 1K | 0.10ms | 0.13ms | **0.06ms (1.7x)** âœ… | **0.05ms (2.0x)** âœ… |
| 10K | 0.67ms | 0.94ms | **0.08ms (8.4x)** âœ… | 0.20ms (3.4x) âœ… |
| 100K | 7.04ms | 10.01ms | **0.86ms (8.2x)** âœ… | 1.31ms (5.4x) âœ… |
| 500K | 35.70ms | 57.42ms | **3.29ms (10.9x)** âœ… | 5.86ms (6.1x) âœ… |

> ğŸ”‘ **Insight:** `packNumberArray` no Bun Ã© atÃ© **11x mais rÃ¡pido** que structuredClone!

---

### SerializaÃ§Ã£o: string[] (Bun)

| Size | structuredClone | JSON | packStringArray |
|------|-----------------|------|-----------------|
| 1K | 0.41ms | **0.10ms (4.1x)** âœ… | 0.33ms (1.2x) âœ… |
| 10K | 4.95ms | **1.56ms (3.2x)** âœ… | 6.28ms âŒ |
| 100K | 64.47ms | **10.14ms (6.4x)** âœ… | 30.87ms (2.1x) âœ… |
| 500K | 477.07ms | **57.01ms (8.4x)** âœ… | ERROR (buffer limit) |

> ğŸ”‘ **Insight:** No Bun, JSON Ã© atÃ© **8x mais rÃ¡pido** que structuredClone para strings!

---

## Node vs Bun: ComparaÃ§Ã£o

### SerializaÃ§Ã£o number[] (100K items)

| MÃ©todo | Node | Bun | Vencedor |
|--------|------|-----|----------|
| structuredClone | 43.23ms | 7.04ms | **Bun 6x** |
| JSON | 35.61ms | 10.01ms | **Bun 3.5x** |
| packNumberArray | 0.87ms | 0.86ms | **Empate** |
| SharedArrayBuffer | 3.64ms | 1.31ms | **Bun 2.8x** |

> ğŸ”‘ **Insight:** packNumberArray Ã© consistentemente rÃ¡pido em ambos runtimes!

### SerializaÃ§Ã£o string[] (100K items)

| MÃ©todo | Node | Bun | Vencedor |
|--------|------|-----|----------|
| structuredClone | 63.34ms | 64.47ms | **Empate** |
| JSON | 16.34ms | 10.14ms | **Bun 1.6x** |
| packStringArray | 46.37ms | 30.87ms | **Bun 1.5x** |

---

## ConclusÃµes

### Quando usar BEE.TURBO:

| CenÃ¡rio | RecomendaÃ§Ã£o |
|---------|-------------|
| CPU-heavy (Math, crypto, parsing) | âœ… **USE BEE.TURBO** - atÃ© 6x speedup |
| CPU-light (x * 2, string concat) | âŒ **USE RAW** - overhead > benefÃ­cio |
| Object transform simples | âŒ **USE RAW** - serializaÃ§Ã£o domina |
| Object transform pesado | âœ… **USE BEE.TURBO** - se compute >> serializaÃ§Ã£o |

### Quando usar AutoPack:

| Tipo de Dados | RecomendaÃ§Ã£o |
|--------------|-------------|
| `number[]` | âœ… **USE packNumberArray** - 50x mais rÃ¡pido |
| `string[]` | âŒ **USE JSON** - mais rÃ¡pido e sem limite |
| `object[]` | âœ… **USE autoPack** - 4x mais rÃ¡pido que structuredClone |

### Regra de Ouro:

```
Se tempo_compute > 10 * tempo_serializaÃ§Ã£o:
    USE workers (turbo)
SenÃ£o:
    USE single-thread (raw)
```

Para 100K objetos:
- SerializaÃ§Ã£o â‰ˆ 77ms (AutoPack)
- Compute deve ser > 770ms para compensar
- Isso = ~7.7Î¼s por item de processamento

---

## Resumo Final

### O que funciona bem:

| Feature | Status | Notas |
|---------|--------|-------|
| **BEE.TURBO (Node)** | âœ… | 5-6x speedup para CPU-heavy |
| **BEE.WORKER.TURBO (Node)** | âœ… | 5-6x speedup para CPU-heavy |
| **BEE.TURBO (Bun)** | âœ… | 2-3x speedup para CPU-heavy |
| **BEE.WORKER.TURBO (Bun)** | âœ… | **4-5x speedup** para CPU-heavy (melhor que Node!) |
| **AutoPack (objetos)** | âœ… | 4-5x mais rÃ¡pido que structuredClone |
| **packNumberArray** | âœ… | 10-50x mais rÃ¡pido que structuredClone |
| **Bun raw performance** | âœ… | 38x mais rÃ¡pido que Node para ops leves |

### O que NÃƒO funciona:

| Feature | Status | Notas |
|---------|--------|-------|
| **CPU-light com workers** | âŒ | Overhead > benefÃ­cio (ambos runtimes) |
| **Object transform simples** | âŒ | SerializaÃ§Ã£o domina (ambos runtimes) |
| **packStringArray 500K+** | âŒ | Limite de 16MB |
| **Piscina no Bun** | âŒ | Incompatibilidade |

### RecomendaÃ§Ãµes de Uso:

```typescript
// âœ… USE para CPU-heavy (>1ms por item)
await beeThreads.turbo(data).map(heavyComputation);

// âŒ NÃƒO use para operaÃ§Ãµes simples
data.map(x => x * 2); // Use raw

// âœ… USE packNumberArray para arrays numÃ©ricos
const packed = packNumberArray(numbers); // 50x mais rÃ¡pido

// âŒ NÃƒO use packStringArray para strings grandes
JSON.stringify(strings); // Mais rÃ¡pido e sem limite
```

---

## PrÃ³ximos Passos

1. âœ… Benchmark Node.js completo
2. âœ… Benchmark Bun completo (BEE.TURBO funciona!)
3. âœ… Comparar Node vs Bun
4. âœ… Piscina incompatÃ­vel com Bun (skipped)
5. â³ Aumentar limite packStringArray ou usar JSON como fallback
6. â³ Adicionar detecÃ§Ã£o automÃ¡tica de "vale a pena usar workers"
